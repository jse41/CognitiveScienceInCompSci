Franz der waal



Try to define my own moral code, how does my definition of morality fall apart 

-- > scale it to other beings, people, cars animals



Is the term of morality even useful? 



Email Lewiki about modeling human brain with neural network and success and limitation 



# Franz de Waal

## Moral Behavior in Animals 

de Waal has done extensive research about morality in specifically primates, mostly chimpanzees, who are some of our own closest genetic kin. Here he finds a seemingly innate sense of fairness existing in animals, where animals are willing to cooperate to make sure they are all able to survive. It goes beyond this so much so that they understand reciprocation, and even the demanding of fairness to exist among their own species. 



## The Existence of the Alpha Male and Learning Algorithms 

There is a lot of energy in the Computer Science world right now in how to improve learning algorithms. This typically comes from combining attributes of multiple already strong preforming algorithms, to create an even better preforming algorithm. Patents are being issued to those who have turned to biology to find learning algorithms where the best performance models are are coupled like DNA strands, where the two top preforming algorithms are joined. The idea of the alpha male being wrongly depicted that de Waal spoke of seems to be relevant here. What is interesting in de Waal's findings is that it is not necessarily strength that determines an alpha male, but what is far more important is the perception by others and connections among the group. I think this idea will be very important in the coming years for Computer Science. There is a lot of energy going into distributed active learning, and if instead of trying to find a model which dominates the rest, the idea of have a society of models, where they learn together and make decisions based on a group, seems extremely promising. I think this acknowledgement of others. 



## What is a Smart AI? 

If we consider a smart AI to be human like, then would we expect better AIs to make more mistakes. Mistakes are just part of who we are, some are biological blind spots, other are byproducts of our brain, focus, and memories skewing reality. 



## Computer Science, Skipping a few steps 

I find it odd that we already have computer that can outperform humans in certain tasks, but still lack some seemingly fundamental abilities (such as empathy and responsibility). Socialization is such a key part of humanity, where groups, belonging, cooperation is so deeply ingrained in us and in our success that generating an intelligence based around isolation seems wrong. 